# qwen-vl-text-extractor
AI OCR Extractor is a fast, local OCR app built with Streamlit and powered by the Qwen 2.5 VL 3B model via Ollama. It converts images to clean text instantly with zero cloud use. Designed for low-capacity systems, but easily upgradeable to larger, more accurate models like 7B, 14B, or newer VLMs.

## ðŸš€ Features

- **Local OCR Processing** â€“ No cloud required, secure for confidential data.
- **Fast Image-to-Text Conversion** â€“ Real-time streaming of extracted text.
- **Smart Preprocessing Pipeline** â€“ Auto-resize, grayscale, and adaptive thresholding for better OCR results.
- **Dark-Themed UI** â€“ Modern, sleek interface built with Streamlit.
- **Model Upgradeable** â€“ Easily switch to larger, more accurate VLMs via Ollama.

---

## ðŸ›  Tech Stack

- **Python**  
- **Streamlit** â€“ Web UI  
- **OpenCV** â€“ Image preprocessing  
- **Pillow (PIL)** â€“ Image handling  
- **NumPy** â€“ Array operations  
- **Requests** â€“ Model API communication  
- **Ollama** â€“ Local model runtime  

---

Install Ollama

Follow the instructions at [Ollama Docs](https://ollama.com/docs/installation)

download the model : ollama pull qwen2.5vl:3b 

---
Run the App

streamlit run qwen_vit.py
